{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pair RDDs contains records consisting of key and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local', 'test_app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['a', 'b', 'c', 'e', 'i', 'o']\n",
    "rdd = sc.parallelize(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x): return 1 if x in ('a', 'e', 'i', 'o', 'u') else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 0), ('c', 0), ('e', 1), ('i', 1), ('o', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd = rdd.map(lambda x: (x, test(x)))\n",
    "pair_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'e', 'i', 'o']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd.values().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD.keyBy(func) \n",
    "1. keyBy() transformation creates a tuple consisting of key, value pair.\n",
    "2. key is derived by function we pass \n",
    "3. value is complete tuple from which key was derived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['filamentA', '100W', 605],\n",
      " ['filamentB', '100W', 683],\n",
      " ['filamentB', '100W', 691],\n",
      " ['filamentB', '200W', 561],\n",
      " ['filamentA', '200W', 530],\n",
      " ['filamentA', '100W', 619],\n",
      " ['filamentB', '100W', 686],\n",
      " ['filamentB', '200W', 600],\n",
      " ['filamentB', '100W', 696],\n",
      " ['filamentA', '200W', 579],\n",
      " ['filamentA', '200W', 520],\n",
      " ['filamentA', '100W', 622],\n",
      " ['filamentA', '100W', 668],\n",
      " ['filamentB', '200W', 569],\n",
      " ['filamentB', '200W', 555],\n",
      " ['filamentA', '200W', 541]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "filDataSingle = [['filamentA','100W',605],['filamentB','100W',683], ['filamentB','100W',691], ['filamentB','200W',561],['filamentA','200W',530], ['filamentA','100W',619],['filamentB','100W',686], ['filamentB','200W',600],['filamentB','100W',696], ['filamentA','200W',579],['filamentA','200W',520], ['filamentA','100W',622], ['filamentA','100W',668], ['filamentB','200W',569],['filamentB','200W',555],['filamentA','200W',541]]\n",
    "pprint.pprint(filDataSingle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', ['filamentA', '100W', 605]),\n",
       " ('filamentB', ['filamentB', '100W', 683]),\n",
       " ('filamentB', ['filamentB', '100W', 691]),\n",
       " ('filamentB', ['filamentB', '200W', 561]),\n",
       " ('filamentA', ['filamentA', '200W', 530]),\n",
       " ('filamentA', ['filamentA', '100W', 619]),\n",
       " ('filamentB', ['filamentB', '100W', 686]),\n",
       " ('filamentB', ['filamentB', '200W', 600]),\n",
       " ('filamentB', ['filamentB', '100W', 696]),\n",
       " ('filamentA', ['filamentA', '200W', 579]),\n",
       " ('filamentA', ['filamentA', '200W', 520]),\n",
       " ('filamentA', ['filamentA', '100W', 622]),\n",
       " ('filamentA', ['filamentA', '100W', 668]),\n",
       " ('filamentB', ['filamentB', '200W', 569]),\n",
       " ('filamentB', ['filamentB', '200W', 555]),\n",
       " ('filamentA', ['filamentA', '200W', 541])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata = sc.parallelize(filDataSingle)\n",
    "f = fdata.keyBy(lambda x: x[0])\n",
    "f.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD.mapValues(func)\n",
    "    1. mapValues() transformation passes each value in Pair RDD through a function w/o changing its key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 606),\n",
       " ('filamentB', 684),\n",
       " ('filamentB', 692),\n",
       " ('filamentB', 562),\n",
       " ('filamentA', 531),\n",
       " ('filamentA', 620),\n",
       " ('filamentB', 687),\n",
       " ('filamentB', 601),\n",
       " ('filamentB', 697),\n",
       " ('filamentA', 580),\n",
       " ('filamentA', 521),\n",
       " ('filamentA', 623),\n",
       " ('filamentA', 669),\n",
       " ('filamentB', 570),\n",
       " ('filamentB', 556),\n",
       " ('filamentA', 542)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.mapValues(lambda x: x[2] + 1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD.flatMapValues(func)\n",
    "    1. passes each value from Pair Rdd to a func w/o changing its key and produces a flattened list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Delhi', 32),\n",
       " ('Delhi', 36),\n",
       " ('Kolkata', 23),\n",
       " ('Kolkata', 45),\n",
       " ('Kolkata', 12),\n",
       " ('Mumbai', 34)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = sc.parallelize(['Delhi, 32|36', 'Kolkata, 23|45|12', 'Mumbai, 34,23,34'])\n",
    "kvpairs = l.map(lambda x:x.split(','))\n",
    "# print kvpairs\n",
    "kvpairs.flatMapValues(lambda x: x.split('|')).map(lambda x:(x[0], int(x[1]))).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD.groupByKey(numPartitions, partitionFunc=<hash_fn>)\n",
    "\n",
    "1. groups the values by key in each key-value PAir RDD\n",
    "2. numPartitions ~ how many groups is has to create\n",
    "3. partitionFunc ~ defaults to sparks's built-in hash partitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('India', <pyspark.resultiterable.ResultIterable object at 0x117c73610>), ('USA', <pyspark.resultiterable.ResultIterable object at 0x117c63bd0>), ('UK', <pyspark.resultiterable.ResultIterable object at 0x117c639d0>)]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([\n",
    "    (\"USA\", 1), (\"USA\", 2), (\"India\", 1),\n",
    "    (\"UK\", 1), (\"India\", 4), (\"India\", 9),\n",
    "    (\"USA\", 8), (\"USA\", 3), (\"India\", 4),\n",
    "    (\"UK\", 6), (\"UK\", 9), (\"UK\", 5)])\n",
    "x = x.groupByKey()\n",
    "print x.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India', [1, 4, 9, 4]), ('USA', [1, 2, 8, 3]), ('UK', [1, 6, 9, 5])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mapValues(lambda y: [a for a in y]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India', 4.5), ('USA', 3.5), ('UK', 5.25)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.mapValues(lambda y: sum([a for a in y])/float(len(y)))\n",
    "x.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD.reduceByKey(func, numPartitions, partitionFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India', 18), ('USA', 14), ('UK', 21)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([\n",
    "    (\"USA\", 1), (\"USA\", 2), (\"India\", 1),\n",
    "    (\"UK\", 1), (\"India\", 4), (\"India\", 9),\n",
    "    (\"USA\", 8), (\"USA\", 3), (\"India\", 4),\n",
    "    (\"UK\", 6), (\"UK\", 9), (\"UK\", 5)])\n",
    "tupls = x.reduceByKey(lambda x, y: x+y)\n",
    "tupls.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India', 1),\n",
       " ('India', 4),\n",
       " ('India', 9),\n",
       " ('India', 4),\n",
       " ('UK', 1),\n",
       " ('UK', 6),\n",
       " ('UK', 9),\n",
       " ('UK', 5),\n",
       " ('USA', 1),\n",
       " ('USA', 2),\n",
       " ('USA', 8),\n",
       " ('USA', 3)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sortByKey(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext \n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(filDataSingle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"_1\", \"filament_type\").withColumnRenamed(\"_2\", \"wattage\").withColumnRenamed(\"_3\", \"lifetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(filament_type=u'filamentB', avg(lifetime)=630.125),\n",
       " Row(filament_type=u'filamentA', avg(lifetime)=585.5)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.groupBy(\"filament_type\").agg({\"lifetime\":\"avg\"})\n",
    "a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[20] at javaToPython at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Avg with PairRDDs based on filament type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filDataRDD = sc.parallelize(filDataSingle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', [605, 1]),\n",
       " ('filamentB', [683, 1]),\n",
       " ('filamentB', [691, 1]),\n",
       " ('filamentB', [561, 1]),\n",
       " ('filamentA', [530, 1])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil = filDataRDD.map(lambda x: (x[0], [x[2],1]))\n",
    "fil.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', 630.125), ('filamentA', 585.5)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil2 = fil.reduceByKey(lambda x,y:[x[0]+y[0], x[1] + y[1]])\n",
    "fil2.map(lambda l: (l[0], float(l[1][0])/l[1][1])).take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate Mean value based on Power type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100W', 658.75), ('200W', 556.875)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil2 = filDataRDD.map(lambda x: (x[1], [x[2], 1]))\n",
    "fil22 = fil2.reduceByKey(lambda x,y:[x[0] +y[0], x[1] + y[1]])\n",
    "fil22.map(lambda l: (l[0], float(l[1][0])/l[1][1])).take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Mean Lifetime Based on Filament Type And Power #exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['si1', 'Robin', 'M'],\n",
      " ['si2', 'Maria', 'F'],\n",
      " ['si3', 'Julie', 'F'],\n",
      " ['si4', 'Bob', 'M'],\n",
      " ['si6', 'William', 'M']]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "studentsData = [['si1','Robin','M'],['si2','Maria','F'],['si3','Julie','F'], ['si4','Bob',  'M'], ['si6','William','M']]\n",
    "subjectsData = [['Python', 'si1'], ['Java', 'si3'], ['Java', 'si1'],['Python', 'si2'],['Ruby', 'si3'],['C++', 'si4'],['C', 'si5'],['Python', 'si4'],['Java', 'si2']]\n",
    "pprint.pprint(studentsData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Python', 'si1'],\n",
      " ['Java', 'si3'],\n",
      " ['Java', 'si1'],\n",
      " ['Python', 'si2'],\n",
      " ['Ruby', 'si3'],\n",
      " ['C++', 'si4'],\n",
      " ['C', 'si5'],\n",
      " ['Python', 'si4'],\n",
      " ['Java', 'si2']]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(subjectsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('si1', ['si1', 'Robin', 'M']),\n",
       " ('si2', ['si2', 'Maria', 'F']),\n",
       " ('si3', ['si3', 'Julie', 'F']),\n",
       " ('si4', ['si4', 'Bob', 'M']),\n",
       " ('si6', ['si6', 'William', 'M'])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentsRDD = sc.parallelize(studentsData, 2).keyBy(lambda x:x[0])\n",
    "studentsRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectsRDD = sc.parallelize(subjectsData, 2).keyBy(lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('si3', (['si3', 'Julie', 'F'], ['Java', 'si3'])),\n",
       " ('si3', (['si3', 'Julie', 'F'], ['Ruby', 'si3'])),\n",
       " ('si2', (['si2', 'Maria', 'F'], ['Python', 'si2'])),\n",
       " ('si2', (['si2', 'Maria', 'F'], ['Java', 'si2'])),\n",
       " ('si1', (['si1', 'Robin', 'M'], ['Python', 'si1'])),\n",
       " ('si1', (['si1', 'Robin', 'M'], ['Java', 'si1'])),\n",
       " ('si4', (['si4', 'Bob', 'M'], ['C++', 'si4'])),\n",
       " ('si4', (['si4', 'Bob', 'M'], ['Python', 'si4']))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentsRDD.join(subjectsRDD).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('si3', (['si3', 'Julie', 'F'], ['Java', 'si3'])),\n",
       " ('si3', (['si3', 'Julie', 'F'], ['Ruby', 'si3'])),\n",
       " ('si2', (['si2', 'Maria', 'F'], ['Python', 'si2'])),\n",
       " ('si2', (['si2', 'Maria', 'F'], ['Java', 'si2'])),\n",
       " ('si6', (['si6', 'William', 'M'], None)),\n",
       " ('si1', (['si1', 'Robin', 'M'], ['Python', 'si1'])),\n",
       " ('si1', (['si1', 'Robin', 'M'], ['Java', 'si1'])),\n",
       " ('si4', (['si4', 'Bob', 'M'], ['C++', 'si4'])),\n",
       " ('si4', (['si4', 'Bob', 'M'], ['Python', 'si4']))]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentsRDD.leftOuterJoin(subjectsRDD).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('si3', (['si3', 'Julie', 'F'], ['Java', 'si3'])),\n",
       " ('si3', (['si3', 'Julie', 'F'], ['Ruby', 'si3'])),\n",
       " ('si2', (['si2', 'Maria', 'F'], ['Python', 'si2'])),\n",
       " ('si2', (['si2', 'Maria', 'F'], ['Java', 'si2'])),\n",
       " ('si1', (['si1', 'Robin', 'M'], ['Python', 'si1'])),\n",
       " ('si1', (['si1', 'Robin', 'M'], ['Java', 'si1'])),\n",
       " ('si5', (None, ['C', 'si5'])),\n",
       " ('si4', (['si4', 'Bob', 'M'], ['C++', 'si4'])),\n",
       " ('si4', (['si4', 'Bob', 'M'], ['Python', 'si4']))]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentsRDD.rightOuterJoin(subjectsRDD).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('si3', (['si3', 'Julie', 'F'], ['Java', 'si3'])),\n",
       " ('si3', (['si3', 'Julie', 'F'], ['Ruby', 'si3'])),\n",
       " ('si2', (['si2', 'Maria', 'F'], ['Python', 'si2'])),\n",
       " ('si2', (['si2', 'Maria', 'F'], ['Java', 'si2'])),\n",
       " ('si6', (['si6', 'William', 'M'], None)),\n",
       " ('si1', (['si1', 'Robin', 'M'], ['Python', 'si1'])),\n",
       " ('si1', (['si1', 'Robin', 'M'], ['Java', 'si1'])),\n",
       " ('si5', (None, ['C', 'si5'])),\n",
       " ('si4', (['si4', 'Bob', 'M'], ['C++', 'si4'])),\n",
       " ('si4', (['si4', 'Bob', 'M'], ['Python', 'si4']))]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentsRDD.fullOuterJoin(subjectsRDD).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
